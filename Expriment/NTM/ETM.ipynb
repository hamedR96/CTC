{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[{}0-9]'.format(string.punctuation), ' ', text)\n",
    "    text=re.sub(r'[^A-Za-z0-9 ]+', ' ', text)\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    text = [WordNetLemmatizer().lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e2cf8bb38b542a881d8f2d7899496ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "df=pd.DataFrame({\"content\":newsgroups[\"data\"]})\n",
    "\n",
    "\n",
    "df[\"content\"]=df[\"content\"].swifter.apply(lambda x: preprocess_text(x))\n",
    "df['content_length'] = df['content'].str.len()\n",
    "\n",
    "df = df[df['content_length'] > 100]\n",
    "df = df[df['content_length'] < 2000]\n",
    "\n",
    "df=df[[\"content\"]].reset_index(drop=True).reset_index().rename(columns={\"index\":\"id\"})\n",
    "documents=df.content.to_list()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "num_topics=50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from embedded_topic_model.utils import preprocessing,embedding\n",
    "\n",
    "# Preprocessing the dataset\n",
    "vocabulary, train_dataset, _, = preprocessing.create_etm_datasets(\n",
    "    documents,\n",
    "    min_df=0.01,\n",
    "    max_df=0.75,\n",
    "    train_size=0.85,\n",
    ")\n",
    "\n",
    "\n",
    "wv = embedding.create_word2vec_embedding_from_dataset(documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics before training: [['since', 'good', 'force', 'ii', 'run', 'standard', 'everything', 'product', 'want', 'drop'], ['manual', 'much', 'could', 'memory', 'couple', 'keep', 'btw', 'designed', 'force', 'love']]\n",
      "Epoch 1 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 268.74 - NELBO: 268.74\n",
      "Epoch 2 - Learning Rate: 0.005 - KL theta: 0.06 - Rec loss: 267.55 - NELBO: 267.61\n",
      "Epoch 3 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 266.56 - NELBO: 266.57\n",
      "Epoch 4 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 265.55 - NELBO: 265.55\n",
      "Epoch 5 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 264.64 - NELBO: 264.64\n",
      "Epoch 6 - Learning Rate: 0.005 - KL theta: 0.0 - Rec loss: 263.76 - NELBO: 263.76\n",
      "Epoch 7 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 263.01 - NELBO: 263.02\n",
      "Epoch 8 - Learning Rate: 0.005 - KL theta: 0.01 - Rec loss: 262.23 - NELBO: 262.24\n",
      "Epoch 9 - Learning Rate: 0.005 - KL theta: 0.02 - Rec loss: 261.55 - NELBO: 261.57\n",
      "Epoch 10 - Learning Rate: 0.005 - KL theta: 0.04 - Rec loss: 261.03 - NELBO: 261.07\n",
      "Topics: [['get', 'make', 'anyone', 'please', 'know', 'want', 'could', 'time', 'good', 'work'], ['would', 'one', 'anyone', 'could', 'system', 'time', 'problem', 'know', 'want', 'back']]\n",
      "Epoch 11 - Learning Rate: 0.005 - KL theta: 0.08 - Rec loss: 260.4 - NELBO: 260.48\n",
      "Epoch 12 - Learning Rate: 0.005 - KL theta: 0.16 - Rec loss: 259.81 - NELBO: 259.97\n",
      "Epoch 13 - Learning Rate: 0.005 - KL theta: 0.22 - Rec loss: 259.37 - NELBO: 259.59\n",
      "Epoch 14 - Learning Rate: 0.005 - KL theta: 0.35 - Rec loss: 258.92 - NELBO: 259.27\n",
      "Epoch 15 - Learning Rate: 0.005 - KL theta: 0.23 - Rec loss: 258.63 - NELBO: 258.86\n",
      "Epoch 16 - Learning Rate: 0.005 - KL theta: 0.2 - Rec loss: 258.44 - NELBO: 258.64\n",
      "Epoch 17 - Learning Rate: 0.005 - KL theta: 0.17 - Rec loss: 258.18 - NELBO: 258.35\n",
      "Epoch 18 - Learning Rate: 0.005 - KL theta: 0.18 - Rec loss: 257.93 - NELBO: 258.11\n",
      "Epoch 19 - Learning Rate: 0.005 - KL theta: 0.2 - Rec loss: 257.73 - NELBO: 257.93\n",
      "Epoch 20 - Learning Rate: 0.005 - KL theta: 0.2 - Rec loss: 257.64 - NELBO: 257.84\n",
      "Topics: [['get', 'make', 'one', 'first', 'would', 'think', 'good', 'want', 'right', 'know'], ['would', 'one', 'problem', 'anyone', 'system', 'know', 'like', 'could', 'well', 'time']]\n",
      "Epoch 21 - Learning Rate: 0.005 - KL theta: 0.23 - Rec loss: 257.39 - NELBO: 257.62\n",
      "Epoch 22 - Learning Rate: 0.005 - KL theta: 0.3 - Rec loss: 257.14 - NELBO: 257.44\n",
      "Epoch 23 - Learning Rate: 0.005 - KL theta: 0.37 - Rec loss: 256.91 - NELBO: 257.28\n",
      "Epoch 24 - Learning Rate: 0.005 - KL theta: 0.46 - Rec loss: 256.75 - NELBO: 257.21\n",
      "Epoch 25 - Learning Rate: 0.005 - KL theta: 0.53 - Rec loss: 256.51 - NELBO: 257.04\n",
      "Epoch 26 - Learning Rate: 0.005 - KL theta: 0.57 - Rec loss: 256.26 - NELBO: 256.83\n",
      "Epoch 27 - Learning Rate: 0.005 - KL theta: 0.54 - Rec loss: 256.16 - NELBO: 256.7\n",
      "Epoch 28 - Learning Rate: 0.005 - KL theta: 0.5 - Rec loss: 256.03 - NELBO: 256.53\n",
      "Epoch 29 - Learning Rate: 0.005 - KL theta: 0.5 - Rec loss: 255.87 - NELBO: 256.37\n",
      "Epoch 30 - Learning Rate: 0.005 - KL theta: 0.56 - Rec loss: 255.7 - NELBO: 256.26\n",
      "Topics: [['people', 'get', 'one', 'think', 'first', 'make', 'right', 'good', 'game', 'want'], ['would', 'one', 'problem', 'like', 'system', 'anyone', 'know', 'file', 'well', 'window']]\n",
      "Epoch 31 - Learning Rate: 0.005 - KL theta: 0.7 - Rec loss: 255.26 - NELBO: 255.96\n",
      "Epoch 32 - Learning Rate: 0.005 - KL theta: 0.82 - Rec loss: 255.05 - NELBO: 255.87\n",
      "Epoch 33 - Learning Rate: 0.005 - KL theta: 0.86 - Rec loss: 254.84 - NELBO: 255.7\n",
      "Epoch 34 - Learning Rate: 0.005 - KL theta: 0.84 - Rec loss: 254.63 - NELBO: 255.47\n",
      "Epoch 35 - Learning Rate: 0.005 - KL theta: 0.76 - Rec loss: 254.59 - NELBO: 255.35\n",
      "Epoch 36 - Learning Rate: 0.005 - KL theta: 0.76 - Rec loss: 254.43 - NELBO: 255.19\n",
      "Epoch 37 - Learning Rate: 0.005 - KL theta: 0.86 - Rec loss: 254.23 - NELBO: 255.09\n",
      "Epoch 38 - Learning Rate: 0.005 - KL theta: 0.98 - Rec loss: 254.0 - NELBO: 254.98\n",
      "Epoch 39 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 253.8 - NELBO: 254.85\n",
      "Epoch 40 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 253.67 - NELBO: 254.72\n",
      "Topics: [['people', 'one', 'right', 'think', 'get', 'first', 'good', 'make', 'time', 'say'], ['problem', 'would', 'file', 'like', 'system', 'window', 'one', 'anyone', 'card', 'use']]\n",
      "Epoch 41 - Learning Rate: 0.005 - KL theta: 0.93 - Rec loss: 253.54 - NELBO: 254.47\n",
      "Epoch 42 - Learning Rate: 0.005 - KL theta: 0.8 - Rec loss: 253.75 - NELBO: 254.55\n",
      "Epoch 43 - Learning Rate: 0.005 - KL theta: 0.84 - Rec loss: 253.68 - NELBO: 254.52\n",
      "Epoch 44 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 253.35 - NELBO: 254.37\n",
      "Epoch 45 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 253.1 - NELBO: 254.29\n",
      "Epoch 46 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 253.07 - NELBO: 254.25\n",
      "Epoch 47 - Learning Rate: 0.005 - KL theta: 1.04 - Rec loss: 253.05 - NELBO: 254.09\n",
      "Epoch 48 - Learning Rate: 0.005 - KL theta: 0.87 - Rec loss: 253.2 - NELBO: 254.07\n",
      "Epoch 49 - Learning Rate: 0.005 - KL theta: 0.84 - Rec loss: 253.32 - NELBO: 254.16\n",
      "Epoch 50 - Learning Rate: 0.005 - KL theta: 1.04 - Rec loss: 252.87 - NELBO: 253.91\n",
      "Topics: [['one', 'would', 'right', 'people', 'time', 'get', 'think', 'make', 'may', 'know'], ['problem', 'would', 'work', 'file', 'like', 'use', 'get', 'window', 'system', 'anyone']]\n",
      "Epoch 51 - Learning Rate: 0.005 - KL theta: 1.2 - Rec loss: 252.77 - NELBO: 253.97\n",
      "Epoch 52 - Learning Rate: 0.005 - KL theta: 1.28 - Rec loss: 252.65 - NELBO: 253.93\n",
      "Epoch 53 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 252.5 - NELBO: 253.67\n",
      "Epoch 54 - Learning Rate: 0.005 - KL theta: 0.94 - Rec loss: 252.84 - NELBO: 253.78\n",
      "Epoch 55 - Learning Rate: 0.005 - KL theta: 0.86 - Rec loss: 252.85 - NELBO: 253.71\n",
      "Epoch 56 - Learning Rate: 0.005 - KL theta: 0.89 - Rec loss: 252.76 - NELBO: 253.65\n",
      "Epoch 57 - Learning Rate: 0.005 - KL theta: 1.03 - Rec loss: 252.7 - NELBO: 253.73\n",
      "Epoch 58 - Learning Rate: 0.005 - KL theta: 1.22 - Rec loss: 252.37 - NELBO: 253.59\n",
      "Epoch 59 - Learning Rate: 0.005 - KL theta: 1.28 - Rec loss: 252.27 - NELBO: 253.55\n",
      "Epoch 60 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 252.35 - NELBO: 253.52\n",
      "Topics: [['one', 'would', 'time', 'right', 'people', 'even', 'think', 'make', 'know', 'get'], ['get', 'work', 'problem', 'use', 'like', 'system', 'would', 'file', 'window', 'one']]\n",
      "Epoch 61 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 252.52 - NELBO: 253.54\n",
      "Epoch 62 - Learning Rate: 0.005 - KL theta: 0.97 - Rec loss: 252.43 - NELBO: 253.4\n",
      "Epoch 63 - Learning Rate: 0.005 - KL theta: 0.97 - Rec loss: 252.35 - NELBO: 253.32\n",
      "Epoch 64 - Learning Rate: 0.005 - KL theta: 1.01 - Rec loss: 252.39 - NELBO: 253.4\n",
      "Epoch 65 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 252.22 - NELBO: 253.34\n",
      "Epoch 66 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 252.25 - NELBO: 253.43\n",
      "Epoch 67 - Learning Rate: 0.005 - KL theta: 1.23 - Rec loss: 252.12 - NELBO: 253.35\n",
      "Epoch 68 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 252.28 - NELBO: 253.43\n",
      "Epoch 69 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 252.19 - NELBO: 253.28\n",
      "Epoch 70 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 252.19 - NELBO: 253.25\n",
      "Topics: [['one', 'would', 'people', 'right', 'think', 'time', 'like', 'even', 'make', 'year'], ['work', 'get', 'use', 'problem', 'system', 'file', 'like', 'one', 'window', 'would']]\n",
      "Epoch 71 - Learning Rate: 0.005 - KL theta: 1.04 - Rec loss: 252.13 - NELBO: 253.17\n",
      "Epoch 72 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 252.19 - NELBO: 253.24\n",
      "Epoch 73 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 252.06 - NELBO: 253.16\n",
      "Epoch 74 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.98 - NELBO: 253.09\n",
      "Epoch 75 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 252.13 - NELBO: 253.22\n",
      "Epoch 76 - Learning Rate: 0.005 - KL theta: 1.08 - Rec loss: 252.07 - NELBO: 253.15\n",
      "Epoch 77 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 252.1 - NELBO: 253.17\n",
      "Epoch 78 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.98 - NELBO: 253.07\n",
      "Epoch 79 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.95 - NELBO: 253.04\n",
      "Epoch 80 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 252.01 - NELBO: 253.07\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'year', 'may'], ['work', 'get', 'problem', 'use', 'system', 'like', 'file', 'one', 'window', 'would']]\n",
      "Epoch 81 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.92 - NELBO: 252.97\n",
      "Epoch 82 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 252.07 - NELBO: 253.09\n",
      "Epoch 83 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 251.89 - NELBO: 252.95\n",
      "Epoch 84 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 252.03 - NELBO: 253.09\n",
      "Epoch 85 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.95 - NELBO: 253.06\n",
      "Epoch 86 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.87 - NELBO: 253.02\n",
      "Epoch 87 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.87 - NELBO: 253.03\n",
      "Epoch 88 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.78 - NELBO: 252.92\n",
      "Epoch 89 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 252.08 - NELBO: 253.15\n",
      "Epoch 90 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.89 - NELBO: 253.01\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'year', 'make'], ['work', 'get', 'use', 'problem', 'system', 'file', 'would', 'like', 'window', 'one']]\n",
      "Epoch 91 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.86 - NELBO: 252.99\n",
      "Epoch 92 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.85 - NELBO: 253.0\n",
      "Epoch 93 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.82 - NELBO: 252.97\n",
      "Epoch 94 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.7 - NELBO: 252.84\n",
      "Epoch 95 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.9 - NELBO: 252.97\n",
      "Epoch 96 - Learning Rate: 0.005 - KL theta: 1.04 - Rec loss: 251.89 - NELBO: 252.93\n",
      "Epoch 97 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.87 - NELBO: 252.92\n",
      "Epoch 98 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.83 - NELBO: 252.94\n",
      "Epoch 99 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 251.77 - NELBO: 252.95\n",
      "Epoch 100 - Learning Rate: 0.005 - KL theta: 1.23 - Rec loss: 251.63 - NELBO: 252.86\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'make', 'even'], ['work', 'get', 'use', 'problem', 'system', 'file', 'would', 'like', 'please', 'window']]\n",
      "Epoch 101 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 251.68 - NELBO: 252.86\n",
      "Epoch 102 - Learning Rate: 0.005 - KL theta: 1.08 - Rec loss: 251.77 - NELBO: 252.85\n",
      "Epoch 103 - Learning Rate: 0.005 - KL theta: 0.99 - Rec loss: 251.97 - NELBO: 252.96\n",
      "Epoch 104 - Learning Rate: 0.005 - KL theta: 1.03 - Rec loss: 251.83 - NELBO: 252.86\n",
      "Epoch 105 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.68 - NELBO: 252.83\n",
      "Epoch 106 - Learning Rate: 0.005 - KL theta: 1.24 - Rec loss: 251.65 - NELBO: 252.89\n",
      "Epoch 107 - Learning Rate: 0.005 - KL theta: 1.27 - Rec loss: 251.59 - NELBO: 252.86\n",
      "Epoch 108 - Learning Rate: 0.005 - KL theta: 1.21 - Rec loss: 251.64 - NELBO: 252.85\n",
      "Epoch 109 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.64 - NELBO: 252.76\n",
      "Epoch 110 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 251.93 - NELBO: 252.95\n",
      "Topics: [['one', 'would', 'right', 'people', 'time', 'think', 'like', 'know', 'year', 'make'], ['work', 'use', 'get', 'problem', 'system', 'would', 'file', 'like', 'window', 'please']]\n",
      "Epoch 111 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.7 - NELBO: 252.79\n",
      "Epoch 112 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.63 - NELBO: 252.82\n",
      "Epoch 113 - Learning Rate: 0.005 - KL theta: 1.25 - Rec loss: 251.61 - NELBO: 252.86\n",
      "Epoch 114 - Learning Rate: 0.005 - KL theta: 1.25 - Rec loss: 251.54 - NELBO: 252.79\n",
      "Epoch 115 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.57 - NELBO: 252.72\n",
      "Epoch 116 - Learning Rate: 0.005 - KL theta: 1.0 - Rec loss: 251.78 - NELBO: 252.78\n",
      "Epoch 117 - Learning Rate: 0.005 - KL theta: 0.97 - Rec loss: 251.85 - NELBO: 252.82\n",
      "Epoch 118 - Learning Rate: 0.005 - KL theta: 1.03 - Rec loss: 251.84 - NELBO: 252.87\n",
      "Epoch 119 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 251.62 - NELBO: 252.8\n",
      "Epoch 120 - Learning Rate: 0.005 - KL theta: 1.29 - Rec loss: 251.51 - NELBO: 252.8\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'year', 'even'], ['work', 'use', 'problem', 'system', 'get', 'file', 'would', 'like', 'one', 'window']]\n",
      "Epoch 121 - Learning Rate: 0.005 - KL theta: 1.25 - Rec loss: 251.52 - NELBO: 252.77\n",
      "Epoch 122 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.62 - NELBO: 252.75\n",
      "Epoch 123 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 251.77 - NELBO: 252.79\n",
      "Epoch 124 - Learning Rate: 0.005 - KL theta: 0.99 - Rec loss: 251.71 - NELBO: 252.7\n",
      "Epoch 125 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.59 - NELBO: 252.64\n",
      "Epoch 126 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.53 - NELBO: 252.63\n",
      "Epoch 127 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.63 - NELBO: 252.72\n",
      "Epoch 128 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.64 - NELBO: 252.74\n",
      "Epoch 129 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.61 - NELBO: 252.74\n",
      "Epoch 130 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 251.57 - NELBO: 252.75\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'year', 'make'], ['work', 'problem', 'use', 'system', 'get', 'file', 'like', 'would', 'one', 'window']]\n",
      "Epoch 131 - Learning Rate: 0.005 - KL theta: 1.21 - Rec loss: 251.47 - NELBO: 252.68\n",
      "Epoch 132 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.6 - NELBO: 252.76\n",
      "Epoch 133 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.57 - NELBO: 252.69\n",
      "Epoch 134 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.68 - NELBO: 252.78\n",
      "Epoch 135 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.58 - NELBO: 252.71\n",
      "Epoch 136 - Learning Rate: 0.005 - KL theta: 1.2 - Rec loss: 251.51 - NELBO: 252.71\n",
      "Epoch 137 - Learning Rate: 0.005 - KL theta: 1.22 - Rec loss: 251.43 - NELBO: 252.65\n",
      "Epoch 138 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.43 - NELBO: 252.59\n",
      "Epoch 139 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.62 - NELBO: 252.67\n",
      "Epoch 140 - Learning Rate: 0.005 - KL theta: 1.0 - Rec loss: 251.72 - NELBO: 252.72\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'year', 'even'], ['work', 'get', 'problem', 'use', 'system', 'file', 'would', 'like', 'please', 'window']]\n",
      "Epoch 141 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.63 - NELBO: 252.72\n",
      "Epoch 142 - Learning Rate: 0.005 - KL theta: 1.21 - Rec loss: 251.41 - NELBO: 252.62\n",
      "Epoch 143 - Learning Rate: 0.005 - KL theta: 1.21 - Rec loss: 251.48 - NELBO: 252.69\n",
      "Epoch 144 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.55 - NELBO: 252.71\n",
      "Epoch 145 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.53 - NELBO: 252.67\n",
      "Epoch 146 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.57 - NELBO: 252.69\n",
      "Epoch 147 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.47 - NELBO: 252.62\n",
      "Epoch 148 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.42 - NELBO: 252.58\n",
      "Epoch 149 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.47 - NELBO: 252.59\n",
      "Epoch 150 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 251.61 - NELBO: 252.67\n",
      "Topics: [['one', 'would', 'right', 'people', 'time', 'think', 'like', 'know', 'year', 'make'], ['work', 'use', 'problem', 'system', 'get', 'would', 'file', 'like', 'window', 'one']]\n",
      "Epoch 151 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 251.56 - NELBO: 252.62\n",
      "Epoch 152 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.48 - NELBO: 252.62\n",
      "Epoch 153 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 251.38 - NELBO: 252.56\n",
      "Epoch 154 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.58 - NELBO: 252.73\n",
      "Epoch 155 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.38 - NELBO: 252.53\n",
      "Epoch 156 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.54 - NELBO: 252.61\n",
      "Epoch 157 - Learning Rate: 0.005 - KL theta: 1.04 - Rec loss: 251.54 - NELBO: 252.58\n",
      "Epoch 158 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 251.48 - NELBO: 252.54\n",
      "Epoch 159 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.54 - NELBO: 252.63\n",
      "Epoch 160 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.4 - NELBO: 252.56\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'year', 'even', 'know'], ['work', 'use', 'problem', 'system', 'get', 'like', 'file', 'would', 'one', 'window']]\n",
      "Epoch 161 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.42 - NELBO: 252.61\n",
      "Epoch 162 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.29 - NELBO: 252.48\n",
      "Epoch 163 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.53 - NELBO: 252.65\n",
      "Epoch 164 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.48 - NELBO: 252.58\n",
      "Epoch 165 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.52 - NELBO: 252.64\n",
      "Epoch 166 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.45 - NELBO: 252.58\n",
      "Epoch 167 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.44 - NELBO: 252.56\n",
      "Epoch 168 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.48 - NELBO: 252.61\n",
      "Epoch 169 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.42 - NELBO: 252.58\n",
      "Epoch 170 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.36 - NELBO: 252.51\n",
      "Topics: [['one', 'would', 'right', 'people', 'think', 'time', 'like', 'know', 'year', 'even'], ['work', 'get', 'use', 'problem', 'system', 'file', 'like', 'would', 'please', 'window']]\n",
      "Epoch 171 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.36 - NELBO: 252.47\n",
      "Epoch 172 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.47 - NELBO: 252.54\n",
      "Epoch 173 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.51 - NELBO: 252.6\n",
      "Epoch 174 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.49 - NELBO: 252.59\n",
      "Epoch 175 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.43 - NELBO: 252.57\n",
      "Epoch 176 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 251.33 - NELBO: 252.51\n",
      "Epoch 177 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 251.31 - NELBO: 252.48\n",
      "Epoch 178 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.51 - NELBO: 252.61\n",
      "Epoch 179 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.4 - NELBO: 252.51\n",
      "Epoch 180 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.48 - NELBO: 252.59\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'year', 'know', 'even'], ['work', 'problem', 'get', 'use', 'system', 'would', 'like', 'file', 'please', 'window']]\n",
      "Epoch 181 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.39 - NELBO: 252.54\n",
      "Epoch 182 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.38 - NELBO: 252.53\n",
      "Epoch 183 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.36 - NELBO: 252.52\n",
      "Epoch 184 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.39 - NELBO: 252.54\n",
      "Epoch 185 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.45 - NELBO: 252.58\n",
      "Epoch 186 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.37 - NELBO: 252.5\n",
      "Epoch 187 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.38 - NELBO: 252.49\n",
      "Epoch 188 - Learning Rate: 0.005 - KL theta: 1.08 - Rec loss: 251.43 - NELBO: 252.51\n",
      "Epoch 189 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 251.53 - NELBO: 252.59\n",
      "Epoch 190 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.4 - NELBO: 252.55\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'like', 'think', 'know', 'year', 'even'], ['work', 'use', 'problem', 'get', 'system', 'would', 'like', 'file', 'one', 'please']]\n",
      "Epoch 191 - Learning Rate: 0.005 - KL theta: 1.24 - Rec loss: 251.29 - NELBO: 252.53\n",
      "Epoch 192 - Learning Rate: 0.005 - KL theta: 1.26 - Rec loss: 251.24 - NELBO: 252.5\n",
      "Epoch 193 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.36 - NELBO: 252.52\n",
      "Epoch 194 - Learning Rate: 0.005 - KL theta: 1.06 - Rec loss: 251.45 - NELBO: 252.51\n",
      "Epoch 195 - Learning Rate: 0.005 - KL theta: 1.03 - Rec loss: 251.4 - NELBO: 252.43\n",
      "Epoch 196 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 251.51 - NELBO: 252.53\n",
      "Epoch 197 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.31 - NELBO: 252.41\n",
      "Epoch 198 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.3 - NELBO: 252.45\n",
      "Epoch 199 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 251.35 - NELBO: 252.52\n",
      "Epoch 200 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.32 - NELBO: 252.48\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'year', 'even'], ['work', 'problem', 'use', 'system', 'get', 'would', 'file', 'like', 'please', 'one']]\n",
      "Epoch 201 - Learning Rate: 0.005 - KL theta: 1.08 - Rec loss: 251.48 - NELBO: 252.56\n",
      "Epoch 202 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.51 - NELBO: 252.56\n",
      "Epoch 203 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.34 - NELBO: 252.45\n",
      "Epoch 204 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.38 - NELBO: 252.51\n",
      "Epoch 205 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.36 - NELBO: 252.55\n",
      "Epoch 206 - Learning Rate: 0.005 - KL theta: 1.22 - Rec loss: 251.24 - NELBO: 252.46\n",
      "Epoch 207 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.32 - NELBO: 252.51\n",
      "Epoch 208 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.28 - NELBO: 252.43\n",
      "Epoch 209 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.49 - NELBO: 252.56\n",
      "Epoch 210 - Learning Rate: 0.005 - KL theta: 1.08 - Rec loss: 251.4 - NELBO: 252.48\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'like', 'think', 'even', 'know', 'year'], ['work', 'use', 'get', 'problem', 'system', 'file', 'would', 'like', 'one', 'window']]\n",
      "Epoch 211 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.39 - NELBO: 252.52\n",
      "Epoch 212 - Learning Rate: 0.005 - KL theta: 1.2 - Rec loss: 251.31 - NELBO: 252.51\n",
      "Epoch 213 - Learning Rate: 0.005 - KL theta: 1.27 - Rec loss: 251.19 - NELBO: 252.46\n",
      "Epoch 214 - Learning Rate: 0.005 - KL theta: 1.26 - Rec loss: 251.26 - NELBO: 252.52\n",
      "Epoch 215 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.33 - NELBO: 252.48\n",
      "Epoch 216 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 251.54 - NELBO: 252.56\n",
      "Epoch 217 - Learning Rate: 0.005 - KL theta: 1.04 - Rec loss: 251.41 - NELBO: 252.45\n",
      "Epoch 218 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.35 - NELBO: 252.44\n",
      "Epoch 219 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 251.26 - NELBO: 252.43\n",
      "Epoch 220 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.22 - NELBO: 252.41\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'know', 'year', 'even'], ['work', 'get', 'problem', 'use', 'system', 'would', 'like', 'file', 'one', 'please']]\n",
      "Epoch 221 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.41 - NELBO: 252.54\n",
      "Epoch 222 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.35 - NELBO: 252.47\n",
      "Epoch 223 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.34 - NELBO: 252.46\n",
      "Epoch 224 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.28 - NELBO: 252.42\n",
      "Epoch 225 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.32 - NELBO: 252.45\n",
      "Epoch 226 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.44 - NELBO: 252.54\n",
      "Epoch 227 - Learning Rate: 0.005 - KL theta: 1.12 - Rec loss: 251.35 - NELBO: 252.47\n",
      "Epoch 228 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.26 - NELBO: 252.45\n",
      "Epoch 229 - Learning Rate: 0.005 - KL theta: 1.2 - Rec loss: 251.3 - NELBO: 252.5\n",
      "Epoch 230 - Learning Rate: 0.005 - KL theta: 1.2 - Rec loss: 251.26 - NELBO: 252.46\n",
      "Topics: [['one', 'would', 'people', 'right', 'like', 'time', 'think', 'know', 'year', 'even'], ['work', 'get', 'problem', 'system', 'use', 'would', 'file', 'like', 'one', 'please']]\n",
      "Epoch 231 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.26 - NELBO: 252.42\n",
      "Epoch 232 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.33 - NELBO: 252.43\n",
      "Epoch 233 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.41 - NELBO: 252.48\n",
      "Epoch 234 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.34 - NELBO: 252.43\n",
      "Epoch 235 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.31 - NELBO: 252.44\n",
      "Epoch 236 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 251.28 - NELBO: 252.45\n",
      "Epoch 237 - Learning Rate: 0.005 - KL theta: 1.18 - Rec loss: 251.24 - NELBO: 252.42\n",
      "Epoch 238 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.17 - NELBO: 252.33\n",
      "Epoch 239 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.38 - NELBO: 252.45\n",
      "Epoch 240 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.31 - NELBO: 252.36\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'think', 'like', 'year', 'know', 'even'], ['work', 'problem', 'use', 'get', 'system', 'would', 'like', 'file', 'one', 'please']]\n",
      "Epoch 241 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 251.35 - NELBO: 252.37\n",
      "Epoch 242 - Learning Rate: 0.005 - KL theta: 1.03 - Rec loss: 251.49 - NELBO: 252.52\n",
      "Epoch 243 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.25 - NELBO: 252.41\n",
      "Epoch 244 - Learning Rate: 0.005 - KL theta: 1.24 - Rec loss: 251.23 - NELBO: 252.47\n",
      "Epoch 245 - Learning Rate: 0.005 - KL theta: 1.28 - Rec loss: 251.13 - NELBO: 252.41\n",
      "Epoch 246 - Learning Rate: 0.005 - KL theta: 1.21 - Rec loss: 251.22 - NELBO: 252.43\n",
      "Epoch 247 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.37 - NELBO: 252.48\n",
      "Epoch 248 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.27 - NELBO: 252.36\n",
      "Epoch 249 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.29 - NELBO: 252.38\n",
      "Epoch 250 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.26 - NELBO: 252.36\n",
      "Topics: [['one', 'would', 'people', 'right', 'like', 'think', 'time', 'know', 'even', 'year'], ['work', 'get', 'problem', 'system', 'use', 'would', 'file', 'like', 'one', 'please']]\n",
      "Epoch 251 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.29 - NELBO: 252.42\n",
      "Epoch 252 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.25 - NELBO: 252.41\n",
      "Epoch 253 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.26 - NELBO: 252.42\n",
      "Epoch 254 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.27 - NELBO: 252.42\n",
      "Epoch 255 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.29 - NELBO: 252.42\n",
      "Epoch 256 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.32 - NELBO: 252.45\n",
      "Epoch 257 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 251.26 - NELBO: 252.43\n",
      "Epoch 258 - Learning Rate: 0.005 - KL theta: 1.2 - Rec loss: 251.25 - NELBO: 252.45\n",
      "Epoch 259 - Learning Rate: 0.005 - KL theta: 1.26 - Rec loss: 251.21 - NELBO: 252.47\n",
      "Epoch 260 - Learning Rate: 0.005 - KL theta: 1.27 - Rec loss: 251.14 - NELBO: 252.41\n",
      "Topics: [['one', 'would', 'people', 'right', 'like', 'time', 'think', 'year', 'know', 'even'], ['work', 'use', 'get', 'problem', 'system', 'would', 'file', 'like', 'one', 'please']]\n",
      "Epoch 261 - Learning Rate: 0.005 - KL theta: 1.21 - Rec loss: 251.22 - NELBO: 252.43\n",
      "Epoch 262 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.27 - NELBO: 252.41\n",
      "Epoch 263 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.36 - NELBO: 252.41\n",
      "Epoch 264 - Learning Rate: 0.005 - KL theta: 1.04 - Rec loss: 251.25 - NELBO: 252.29\n",
      "Epoch 265 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.34 - NELBO: 252.39\n",
      "Epoch 266 - Learning Rate: 0.005 - KL theta: 1.09 - Rec loss: 251.32 - NELBO: 252.41\n",
      "Epoch 267 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.17 - NELBO: 252.33\n",
      "Epoch 268 - Learning Rate: 0.005 - KL theta: 1.15 - Rec loss: 251.29 - NELBO: 252.44\n",
      "Epoch 269 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 251.22 - NELBO: 252.39\n",
      "Epoch 270 - Learning Rate: 0.005 - KL theta: 1.16 - Rec loss: 251.16 - NELBO: 252.32\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'like', 'think', 'know', 'year', 'even'], ['work', 'use', 'get', 'problem', 'system', 'would', 'like', 'file', 'one', 'please']]\n",
      "Epoch 271 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.2 - NELBO: 252.31\n",
      "Epoch 272 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.25 - NELBO: 252.3\n",
      "Epoch 273 - Learning Rate: 0.005 - KL theta: 1.01 - Rec loss: 251.32 - NELBO: 252.33\n",
      "Epoch 274 - Learning Rate: 0.005 - KL theta: 1.03 - Rec loss: 251.3 - NELBO: 252.33\n",
      "Epoch 275 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.28 - NELBO: 252.39\n",
      "Epoch 276 - Learning Rate: 0.005 - KL theta: 1.2 - Rec loss: 251.2 - NELBO: 252.4\n",
      "Epoch 277 - Learning Rate: 0.005 - KL theta: 1.26 - Rec loss: 251.08 - NELBO: 252.34\n",
      "Epoch 278 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.24 - NELBO: 252.43\n",
      "Epoch 279 - Learning Rate: 0.005 - KL theta: 1.13 - Rec loss: 251.28 - NELBO: 252.41\n",
      "Epoch 280 - Learning Rate: 0.005 - KL theta: 1.1 - Rec loss: 251.21 - NELBO: 252.31\n",
      "Topics: [['one', 'would', 'people', 'right', 'like', 'think', 'time', 'know', 'year', 'even'], ['work', 'get', 'use', 'problem', 'system', 'would', 'file', 'one', 'like', 'please']]\n",
      "Epoch 281 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.22 - NELBO: 252.29\n",
      "Epoch 282 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.3 - NELBO: 252.35\n",
      "Epoch 283 - Learning Rate: 0.005 - KL theta: 1.08 - Rec loss: 251.39 - NELBO: 252.47\n",
      "Epoch 284 - Learning Rate: 0.005 - KL theta: 1.19 - Rec loss: 251.2 - NELBO: 252.39\n",
      "Epoch 285 - Learning Rate: 0.005 - KL theta: 1.27 - Rec loss: 251.06 - NELBO: 252.33\n",
      "Epoch 286 - Learning Rate: 0.005 - KL theta: 1.24 - Rec loss: 251.08 - NELBO: 252.32\n",
      "Epoch 287 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.19 - NELBO: 252.33\n",
      "Epoch 288 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 251.36 - NELBO: 252.38\n",
      "Epoch 289 - Learning Rate: 0.005 - KL theta: 1.0 - Rec loss: 251.42 - NELBO: 252.42\n",
      "Epoch 290 - Learning Rate: 0.005 - KL theta: 1.03 - Rec loss: 251.29 - NELBO: 252.32\n",
      "Topics: [['one', 'would', 'people', 'right', 'time', 'like', 'think', 'know', 'year', 'even'], ['work', 'get', 'use', 'system', 'problem', 'would', 'like', 'file', 'one', 'please']]\n",
      "Epoch 291 - Learning Rate: 0.005 - KL theta: 1.11 - Rec loss: 251.27 - NELBO: 252.38\n",
      "Epoch 292 - Learning Rate: 0.005 - KL theta: 1.17 - Rec loss: 251.26 - NELBO: 252.43\n",
      "Epoch 293 - Learning Rate: 0.005 - KL theta: 1.26 - Rec loss: 251.11 - NELBO: 252.37\n",
      "Epoch 294 - Learning Rate: 0.005 - KL theta: 1.24 - Rec loss: 251.07 - NELBO: 252.31\n",
      "Epoch 295 - Learning Rate: 0.005 - KL theta: 1.14 - Rec loss: 251.22 - NELBO: 252.36\n",
      "Epoch 296 - Learning Rate: 0.005 - KL theta: 1.05 - Rec loss: 251.29 - NELBO: 252.34\n",
      "Epoch 297 - Learning Rate: 0.005 - KL theta: 0.99 - Rec loss: 251.32 - NELBO: 252.31\n",
      "Epoch 298 - Learning Rate: 0.005 - KL theta: 1.02 - Rec loss: 251.27 - NELBO: 252.29\n",
      "Epoch 299 - Learning Rate: 0.005 - KL theta: 1.07 - Rec loss: 251.38 - NELBO: 252.45\n"
     ]
    },
    {
     "data": {
      "text/plain": "<embedded_topic_model.models.etm.ETM at 0x13fa4beb0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from embedded_topic_model.models.etm import ETM\n",
    "\n",
    "# Training an ETM instance\n",
    "etm_instance = ETM(\n",
    "    vocabulary,\n",
    "    embeddings=wv, # You can pass here the path to a word2vec file or a KeyedVectors instance\n",
    "    num_topics=num_topics,\n",
    "    epochs=300,\n",
    "    debug_mode=True,\n",
    "    train_embeddings=False, # Optional. If True, ETM will learn word embeddings jointly with\n",
    "                            # topic embeddings. By default, is False. If 'embeddings' argument\n",
    "                            # is being passed, this argument must not be True\n",
    ")\n",
    "\n",
    "etm_instance.fit(train_dataset)\n",
    "#etm_instance._save_model(\"./results/etm/200K\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[['one',\n  'would',\n  'people',\n  'right',\n  'like',\n  'time',\n  'think',\n  'know',\n  'year',\n  'even'],\n ['work',\n  'get',\n  'problem',\n  'use',\n  'system',\n  'would',\n  'file',\n  'like',\n  'one',\n  'please']]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etm_instance.get_topics()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
